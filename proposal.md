# Proposal (2.0)
**Nikolay Nikolov**, Goldsmiths, BSc Creative Computing  
**Dr. Rebecca Friebrink**, Supervisor

#### Title
Usable Machine Learning / Personalized Smartphone Gesture Recognizer

#### Describe the problem(s) you will be working on in your project and explain how they relate to the Learning Outcomes of your degree programme.

Machine learning sharply increased in popularity as of late thanks to abundant data accumulated by Google and others, increase in computing power and algorithms like Deep Learning. As any other new technology it slowly becomes useful outside its initial development niche and is being used in a majority of interesting contexts. At this stage it is solely used by experts of the field or experienced enough computer scientists who can translate research papers to code. But to become a more useful or even groundbreaking consumer tool it needs to be made available to a less technical crowd or experts in other fields (designers, doctors etc.).

Only recently Autodesk announced the future of their software will be more intelligent tools that learn about you and your workflow as much as you learn to use the software. This embodies the spirit of our future tools as a symbiosis of predictive algorithms and human creativity can achieve much more than one or the other by itself.

The next step is bringing these tools to ubiquitous computing devices such as smartphones, smartwatches, IoT devices and so on. In order for them to be usable, they will need to include the appropriate user experience and interaction design. Users need to be able to understand the process of training their own data and get precise intuitive feedback to follow up on errors or provide better data.

One example example would be training gesture recognition on smartphones to be used for personally, by artists for interactive installation, game developers, web developers and so on. As already mentioned above, some of the challenges I will be tackle will be both technical as well as design-driven. I will try to find out how accurate and usable a gesture recognizer could be if built on top of web technologies. Secondly, I will aim to create a short feedback loop between the cycles of training data, aided by intuitive user experience, user interaction and data visualizations. As additional outcomes, I will research and test the limits of such gestures' complexity, i.e. what is the most complex gesture that my machine learning pipeline can handle, can GPS data be considered a gesture (over a longer period of time) or perhaps the shape of our walking (with a smartphone in our pocket).

#### Explain how you will tackle your chosen problem(s). Briefly indicate how you will go about evaluating your results.
The first phase will consist of prototyping and brainstorming the design of the interaction. I will have to conclude what is technically possible and implement and iterate on the chosen features. What follows is a period of user testing and collecting data, and experimentation with different use cases.

In order to achieve satisfactory usability at the end of the project the users must have interacted, understood and practiced a two-way relationship with the tool, as in the software would have been ideally influenced by the user as much as the user by the software. 

